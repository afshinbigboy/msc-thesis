% !TeX root=../../../main.tex

\chapter{مبانی تحقیق}
% دستور زیر باعث عدم‌نمایش شماره صفحه در اولین صفحهٔ این فصل می‌شود.
%\thispagestyle{empty}

در این فصل ابتدا مفاهیم مورد نیاز جهت تعریف مسئله مانند مدل‌های ناهمگنی تومور، روش‌های یافتن درخت تکاملی تومور، روش‌های توالی‌یابی داده مورد بررسی قرار می‌گیرند. در ادامه مدل‌های مورد استفاده برای استنباط درخت تکاملی تومور معرفی می‌شوند. در پایان مفاهیم مرتبط با یادگیری ماشینی، یادگیری عمیق و یادگیری تقویتی به منظور استنباط درخت تکاملی تومور با \gls{datadriven}  توضیح داده می‌شوند.


\section{تنوع ژنتیکی}

\gls{dna} 
یک مولکول بیولوژیکی است که توسط \glspl{nucleotid}  پلیمری شده است. در \gls{dna} چهار نوع \gls{nucleotid} وجود دارد: \gls{adenine}  (\lr{A})، \gls{thymine}  (\lr{T})، \gls{cytosine} (\lr{C}) و
 \gls{guanine} (\lr{G}).
  \gls{dna} اساس توالی اسیدهای آمینه است که پروتئین را تشکیل می‌دهد. یک مولکول \gls{dna} از دو رشته تشکیل شده است. که در \glspl{antiparallel}  هم و درجهت‌های مخالف قرار دارند و ساختاری از مارپیچ دوتایی ایجاد می‌کنند. هر نوع \gls{nucleotid} روی یک رشته با نوع دیگری از \gls{nucleotid} در رشته دیگر مرتبط است: A با T ؛ C با G (شکل \ref{fig:ch_lr:DNA_double_helix}) \cite{alberts2002molecular}. این به عنوان قانون پایه جفت شدن نوکلئوتید‌ها در هر رشته از \gls{dna} شناخته می‌شود.


\begin{figure}[!ht]
	\centerline{\includegraphics[width=11cm]{chaps/lr/DNA_double_helix}}
	\caption{مارپیچ دوگانه \gls{dna}}
	\label{fig:ch_lr:DNA_double_helix}
\end{figure}



همانند سازی \gls{dna} فرآیند تولید دو مولکول \gls{dna} یکسان از مولکول \gls{dna} اصلی است. وقتی تکثیر شروع می‌شود، دو رشته یک مولکول \gls{dna} از یکدیگر جدا می‌شوند و هر رشته به عنوان الگویی برای ساخت نمونه مشابه خود عمل می‌کند. نوکلئوتید‌ها در هر موقعیت از یک رشته با نوع دیگری از \gls{nucleotid} مبتنی بر قانون پایه جفت شدن، به منظور سنتز همتای این رشته، متصل می‌شود. پس از همانند سازی، مولکول \gls{dna} اصلی به دو مولکول یکسان تبدیل می‌شود (شکل \ref{fig:ch_lr:DNA_replication}) \cite{alberts2002molecular}.

\begin{figure}[!ht]
	\centerline{\includegraphics[width=8cm]{chaps/lr/DNA_replication}}
	\caption{همانندسازی \gls{dna}}
	\label{fig:ch_lr:DNA_replication}
\end{figure}





ژن ناحیه‌ای از \gls{dna} است و به عنوان مولکول واحد وراثت شناخته می‌شود. ژن‌های متعددی در ساختار \gls{dna} با عملکرد‌های متفاوت وجود دارد. جهش به تغییر دائمی‌توالی هسته‌ای ژنوم اتلاق می‌شود. جهش‌ها می‌توانند در حین فرآیند تکثیر \gls{dna} و با جفت‌گیری اشتباه در قسمت‌های مختلف \gls{dna} ایجاد می‌شود. انواع مختلفی از جهش‌ها مانند \gls{snm}(\gls{pointmutation})  (شکل \ref{fig:ch_lr:single_nucleotide_mutation}) و  \glspl{singlevariant}  شامل \gls{insertion} ، \gls{deletion}  و \gls{reversion}  (شکل \ref{fig:ch_lr:structural_changes}) وجود دارد. جهش‌های سلولی می‌توانند به بنا بر دلایلی چون مواد شیمیایی، سمیت یا ویروس ایجاد شوند. جهش در یک ژن می‌تواند محصولات آن را تغییر دهد (مانند ایجاد پروتئین متفاوت) یا از عملکرد صحیح ژن جلوگیری کند \cite{alberts2002molecular}.




\begin{figure}[!ht]
	\centerline{\includegraphics[width=10cm]{chaps/lr/single_nucleotide_mutation}}
	\caption{جهش تک‌نوکلئوتیدی}
	\label{fig:ch_lr:single_nucleotide_mutation}
\end{figure}



\begin{figure}[!ht]
	\centerline{\includegraphics[width=10cm]{chaps/lr/structural_changes}}
	\caption{تغییرات ساختاری}
	\label{fig:ch_lr:structural_changes}
\end{figure}




\section{\gls{tumorevolution}}


جهشی که در هر سلول از بدن اتفاق می‌افتد، به استثنای سلول‌های جنسی (اسپرم و تخمک)، جهش \gls{somatic}  نامیده می-شود \cite{somaticMutation}. تجمع جهش بدنی در طول زندگی یک فرد می‌تواند منجر به رشد کنترل نشده مجموعه‌ای از سلول(تومور) شود \cite{nowell1976clonal} و می‌تواند باعث شکل‌گیری سرطان یا بیماری‌های دیگر شود \cite{somaticMutation}. بدلیل تجمع سلول‌های گوناگون، بیش از یک نوع سلول در تومور وجود خواهد داشت. به گروه‌های سلول با مجموعه‌ای از جهش مشخص، کلون یا جمعیت سلولی تومور گفته می‌شود. کلون‌های موجود در تومور از نظر فیلوژنتیک با هم مرتبط هستند و رابطه آنها را می‌توان با یک درخت فیلوژنتیک نشان داد \cite{birbrair2014type}. درخت فیلوژنتیک رابطه تکاملی بین کلون و ترتیب وقوع هر جهش را نشان می‌دهد. به عنوان مثال، شکل\ref{fig:ch_lr:tumor_phylogenetic_tree} :

\begin{itemize}
	\item یک درخت فیلوژنتیک از یک تومور با چهار کلون با برچسب $0$ تا $3$ را نشان می‌دهد.
	\item جهش جدیدی را نشان می‌دهد که در هر کلون در طول تکامل این تومور رخ داده است.
\end{itemize}

 همچنین هر کلون جهشی را در مسیر از کلون بالایی به سمت خود به ارث می‌برد. به عنوان مثال، کلون $0$ جهش‌های
  $m_0$ و	 $m_1$ دارد. کلون $1$ دارای جهش $m_0$، $m_2$، $m_3$ و $m_4$ است.
 
\begin{figure}[!ht]
	\centerline{\includegraphics[width=13cm]{chaps/lr/tumor_phylogenetic_tree}}
	\caption{درخت فیلوژنیک تومور}
	\label{fig:ch_lr:tumor_phylogenetic_tree}
\end{figure}


\section{تکنولوژی‌های توالی‌یابی و \gls{variantallelefrequency}}




تعیین توالی \gls{dna} روشی برای تشخیص ترتیب دقیق \glspl{nucleotid} در یک رشته \gls{dna} است. روش \gls{nextgenerationsequencing}  از تعدادی فناوری مدرن توالی تشکیل شده است که امکان تعیین هزینه و زمان توالی‌یابی را به طور موثر فراهم می-کند. با استفاده از نمونه بیولوژیکی به عنوان ورودی این تکنولوژی‌ها، توالی‌های کوتاه نوکلئوتیدی تولید می‌شود (که به آن \gls{read}  گفته می‌شود). سپس خوانش با استفاده از الگوریتم \gls{alignment}  متنوعی مانند الگوریتم تبدیل \lr{Burrows-Wheeler} با ژنوم مرجع تراز می‌شوند. پس از ترازبندی، می‌توان با جمع‌آوری \glspl{overlappingread}،  توالی \gls{consensus}  ایجاد کرد (شکل \ref{fig:ch_lr:alignment_reading}). در موقعیتی از توالی اجماع به دلیل همپوشانی خوانش ها، ممکن است بیش از یک نوع خوانش از \gls{nucleotid} تراز شده وجود داشته باشد (تعداد کل قرائت مرتبط با یک نوع جهش، را \gls{readcoverage}  نامیده می‌شود). \gls{nucleotid} موجود در این موقعیت به عنوان رایج‌ترین \gls{nucleotid} تراز شده، مشخص می‌شود. به عنوان مثال، در شکل \ref{fig:ch_lr:alignment_reading}، سه آدنین (A)، یک گوانین (G) و یک تیمین (T)  در موقعیت سوم توالی اجماع تراز می‌شوند، سپس \gls{nucleotid} در آن موقعیت به عنوان آدنین (A) تعیین می‌شود. پس از ایجاد توالی اجماع، نوکلئوتیدهای موجود در آن توالی، که متفاوت از ژنوم مرجع هستند، شناسایی شده و به عنوان \gls{somaticsnv}  شناخته می‌شود. با استفاده از نمونه‌های متعدد استخراج شده از یک نمونه تومور، ما می‌توانیم تغییرات بدنی تک نوکلئوتیدی را در هر نمونه با فناوری تعیین توالی‌یابی تشخیص دهیم. نسبت تعداد سلول‌های موجود در یک نمونه حاوی تغییرات بدنی تک نوکلئوتیدی به کل سلول‌ها، فراوانی تغییرات آلل یک تغییر بدنی تک نوکلئوتیدی در این نمونه نامیده می‌شود. مقادیر فراوانی تغییرات آلل برای هر تغییر بدنی تک نوکلئوتیدی  در هر نمونه تومور قابل محاسبه است. ابزارهای زیادی برای بازسازی درخت فیلوژنتیک تومور از مقادیر فراوانی تغییرات آلل تومور به عنوان ورودی الگوریتم استفاده می‌کنند.



\begin{figure}[!ht]
	\centerline{\includegraphics[width=\textwidth]{chaps/lr/alignment_reading}}
	\caption{تشخیص تغییر بدنی تک‌نوکلئوتیدی از طریق خوانش هم‌ترازی}
	\label{fig:ch_lr:alignment_reading}
\end{figure}



\section{ناهمگنی ژنومی تومور}

سرطان بیماری‌ای است که بدلیل ایجاد ناهنجاری‌های اساسی در فرآیند‌های بنیادی سلول مانند \gls{replication}، \gls{differentiation}  و \gls{death} سلول  ایجاد می‌شود \cite{hanahan2011hallmarks}. این ناهنجاری منجر به رشد کنترل نشده تومور و به‌کارگیری بافت غیرسرطانی برای حمایت از این رشد می‌شود. علت اصلی این تغییرات جهش است. جهش یک اصطلاح گسترده است که چندین دسته از تغییرات ژنتیکی را پوشش می‌دهد. هنگام حاملگی، یک جنین دارای یک ژنوم خاص و منحصر به فرد است. این ژنوم که به \gls{germlinegenome} معروف است، می‌تواند با ژنوم انسانی مرجع مقایسه شود. ژنوم انسانی مرجع یک نمونه از ژنوم انسان است و از \gls{dna} چند نفر تشکیل شده است. تفاوت بین ژنوم جوانه‌زنی و ژنوم مرجع به عنوان جهش ژنوم جوانه زنی شناخته می-شود. جهش‌های جوانه زنی می‌توانند مسئول افزایش خطر ابتلا به سرطان باشند \cite{stewart2017world}، اما بندرت خود مسئول مستقیم توسعه تومور هستند. 




معمولاً تومورها در اثر جهش‌های اکتساب شده پس از لقاح، که معروف به جهش‌های بدنی هستند، ایجاد می‌شوند. جهش-های بدنی نتیجه اشتباهات در تکثیر \gls{dna} \cite{behjati2014genome}، قرار گرفتن در معرض جهش‌های با منشأ داخلی یا خارجی یا وارد‌شدن توالی‌های \gls{dna} با منشأ بیرونی بدلیل قرار گرفتن در معرض ویروس است \cite{talbot2004viruses}. غالباً در سرطان، جهش‌های بدنی باعث ایجاد اختلال در روند تکثیر \gls{dna} یا ترمیم آن می‌شوند و حتی جهش‌های بدنی بیشتری ایجاد می‌کنند \cite{stratton2009cancer}. نظریه کلونی بودن سرطان \cite{nowell1976clonal} سرطان را به عنوان یک تک سلولی با منشأ غیرجنسی در نظر می‌گیرد که در اثر تولید مثل فراوان، یک توده متشکل از کلون‌های سلولی گوناگون را ایجاد می‌کند. در این مدل سلولهای توموری با یکدیگر در رقابت هستند و جهش‌های بدنی که مزیت رشد را ایجاد می‌کنند در جمعیت سلول‌های توموری از نسبت بیشتری برخوردار خواهند بود. جهش‌های بدنی که باعث رشد تومور شده و از سلولی به سلولی دیگر منتقل می‌شوند به عنوان \glspl{drivermutation} شناخته می‌شوند. اولین سلولی که دارای جهش راننده بوده و آن را به جهش‌های بعدی منتقل می‌کند به عنوان سلول بنیانگذار شناخته می‌شود. همه فرزندان این سلول بنیانگذار، جهش راننده و هر جهش دیگری را که سلول بنیانگذار قبل از به دست آوردن جهش راننده بدست آورده است، دارند. این جهش‌های دیگر، که مزیتی برای رشد و گسترش تنوع توموری ندارند، به عنوان \glspl{passengermutation} شناخته می‌شوند. شایان ذکر است که تعریف جهش راننده و مسافر به زمینه ژنتیکی و محیطی بستگی دارد. به عنوان مثال، شیمی درمانی \gls{cytotoxic}  (سیتوتوکسیک) می‌تواند باعث تغییر جهش از مسافر به جهش راننده شود و عامل اصلی مقاومت در برابر درمان باشد. همچنین جهش ها را می‌توان بر اساس نوع تغییری که در \gls{dna} ایجاد می‌شود، به طبقات متمایز تقسیم کرد. \gls{snv} جهش‌هایی هستند که یک پایه در ژنوم را به پایه دیگری تغییر می‌دهند. \gls{indel}  درج یا حذف یک بخش \gls{dna} است که می‌تواند کوتاه یا طولانی باشد. از ایندل کوتاه و تغییرات تک نوکلئوتیدی در مجموع به عنوان \glspl{ssm}  یاد می‌شود. در همه قسمت‌های یک ژنوم، از جمله کل کروموزوم‌ها، قابلیت حذف یا کپی شدن قسمتی از ژنوم وجود دارد. تغییرات شماره کپی  به جهشی اتلاق می‌شود که منجر به حذف یا کپی شدن قسمتی از ژنوم می‌شود. \gls{cna} نوعی \gls{singlevariant} هستند که شامل وارونگی (وقتی قسمت بزرگی از ژنوم معکوس شده باشد) و انتقال متعادل (جایی که دو بخش ژنومی مکان‌‌های خود را با یکدیگر تعویض می‌کنند) می‌باشند\cite{stratton2009cancer}. این گونه‌های مختلف جهش مستقل از یکدیگر نیستند و می‌توانند در رابطه با یکدیگر اتفاق بیفتند (به عنوان مثال یک جهش می‌تواند منجر به تقویت یک وارونگی شود). 



تکنیک توالی‌یابی نسل بعدی این امکان را فراهم کرده است تا با صرف هزینه بسیار کم و با استفاده از یک نمونه توموری، توالی‌یابی از \gls{dna} صورت پذیرد و همین امر منجر به تحول گسترده‌ای در زمینه مطالعه تکامل تومور شده زیر امکان نمونه-برداری در تعداد بسیار بالا را از تومور فراهم می‌کند. نمونه‌گیری در حجم بالا این امکان را فراهم آورده است تا ناهمگنی تومور از نقطه منظر ژنتیکی مورد بررسی قرار گیرد و پاسخ به درمان بیماران سرطانی با جزییات بیشتری مورد ارزیابی قرار گیرد.


تقریباً همه نمونه‌های استخراج شده از تومور ترکیبی از سلول ها با ژنوتیپ‌های مختلف را شامل می‌شود. یک نمونه توموری به ندرت فقط شامل بافت سرطانی است زیرا شامل سلول‌های غیر سرطانی از \gls{surroundingstroma}  یا \glspl{Infiltratingimmunecell}  است. مطالعات ژنومیک نشان داده است که حتی در میان سلولهای سرطانی، غالباً زیرجمعیت‌های متعدد سرطانی نیز وجود دارد. به عنوان مثال، در یک مطالعه مهم در سال 2012، گرلینگر و همکارانش \cite{gerlinger2012intratumor} توالی‌یابی ژنوم و تغییرات شماره کپی را از طریق نمونه‌های مکانی مجزا استخراج شده از سرطان کلیه اولیه و نقاط متاستاز ثانویه بدست آورده‌اند. با بررسی  این نمونه‌های متعدد، مشخص شد که یک ناهمگنی ژنتیکی قابل توجهی در تومور وجود دارد. تعداد بسیار زیادی از جهش‌های شناسایی شده در همه سلول‌های توموری مشاهده نشدند و این بدان معناست که این جهش‌ها بیش از آن‌که یک ناحیه کلونی باشند، به صورت یک ناحیه زیر کلونی بوده‌اند. با استفاده از روش‌های پردازش غیراتوماتیک، تغییرات تک نوکلئوتیدی  ها و تغییرات شماره کپی بر اساس نمونه‌هایی که از آن استخراج شده‌اند، به خوشه‌های مجزا دسته‌بندی شده و یک درخت فیلوژنی به آن‌ها نسبت داده شد. بازسازی درخت فیلوژنیک تومور این امکان را فراهم آورد تا سیر تکاملی تومور با استفاده از شاخه‌های مختلف درخت فیلوژنی شامل جهش‌هایی با عملکرد یکسان از سه ژن متفاوت مورد بررسی قرار گیرد. 


در همان سال، یک مطالعه مهم دیگر، "تاریخچه زندگی 21 سرطان پستان`` \cite{nik2012life}، حضور \lr{ITH} را نیز نشان داد. در این مطالعه آنها توالی‌یابی کامل ژنوم را در عمق متوسط \lr{188X} بر روی تومور پستان \lr{PD4120a} انجام دادند. این عمق اجازه می‌دهد تا جمعیت‌های شیوع تا 5٪ کم باشد. آنها مشاهده کردند که تغییرات تک نوکلئوتیدی‌ها در تعداد کمی از خوشه‌های مجزا مشاهده می‌شوند که با توجه به کسر نوع آلل (\lr{VAF}) آنها مشاهده می‌شود، نسبت خواندن ها در یک مکان متفاوت شامل آلل نوع. علاوه بر این، آنها توانستند نشان دهند که برخی از این خوشه‌های مجزا را نمی‌توان با جهش‌های موجود در تمام جمعیت‌های سرطانی توضیح داد، که این نشان دهنده حضور تغییرات تک نوکلئوتیدی‌های تحت کلونال است. در همان زمان، آنها دریافتند که بسیاری از جهش‌ها در تمام سلول‌های سرطانی موجود در نمونه وجود دارد، که نشان می‌دهد جد مشترک اخیر نسبتاً دیر در زمان تکامل رشد کرده است. مشاهده اینکه جهش‌های زیر کلونال به جای توزیع یکنواخت یا مطابق قانون قدرت در خوشه‌های متمایز پیدا شده است، شواهدی را نشان می‌دهد که این جهش‌های زیرکلونالی بیش از آنکه ناشی از تکامل خنثی یا مصنوعات فنی باشد، در زیرمجموعه‌های متمایز ناشی از فشارهای انتخابی یافت می‌شود. نویسندگان همچنین با تأیید اینکه جهش‌های زیر کلونال محدود به تغییرات تک نوکلئوتیدی  نیستند، توانستند حضور تغییرات شماره کپی‌های کلونال و زیرکلونال را تأیید کنند. نویسندگان یک الگوریتم خوشه‌بندی غیر پارامتریک (یک مدل مخلوط فرآیند دیریشله (\lr{DPMM})) را با استدلال قابل توجه دستی برای استنباط فیلوژنی شاخه‌ای از چهار زیر جمعیت سرطانی در آن نمونه منفرد تومور ترکیب کردند. درک معماری ژنتیکی این زیرجمعیت‌ها می‌تواند به مطالعه زیست شناسی سرطان کمک کند و نشان داده شده است که در پیش‌بینی بقا در بسیاری از انواع سرطان مفید است \cite{andor2016pan}. به عنوان مثال، زیرجمعیت‌های مختلف، که توسط مجموعه جهش‌های جسمی حمل شده تعریف می‌شوند، توانایی‌های مختلفی در مقاومت در برابر درمان و متاستاز دارند. برای انجام این کار، باید از یک یا تعداد کمی از نمونه‌های تومور فله، ژنوتیپ‌های موجود در نمونه را شناسایی کرد. این مسئله، تحت عنوان بازسازی زیر کلونال، موضوع اصلی این پایان‌نامه است. مطالعات پیشگام که نشان داد \lr{ITH} برای انجام این بازسازی به استدلال دستی قابل توجهی نیاز دارد. استدلال دستی کند، مستعد خطا است و به تخصص قابل توجهی نیاز دارد. مزایای بازسازی کاملاً خودکار بدیهی است. این بخش پیش زمینه مشکل بازسازی زیر کلونال، چگونگی پرداختن به آن برای انواع مختلف جهش، خصوصیات اصلی الگوریتم‌های بازسازی زیر کلونال و خلاصه‌ای از کارهای موجود در این زمینه را توصیف می‌کند.

\section{بازسازی زیر کلونال}

بازسازی زیر کلونال سعی دارد ژنوتیپ‌های موجود در تومور را از تعداد کمی از نمونه‌های توالی \gls{dna} از آن تومور استنباط کند. تعداد ژنوتیپ‌های موجود در تومور از قبل مشخص نیست. این ژنوتیپ‌های زیر کلونال به طور معمول با جهش‌هایی که در مقایسه با ژنوم خط جوانه‌ای دارند، توصیف می‌شوند. ژنوم جوانه‌زنی علاوه بر نمونه(های) تومور، با تعیین توالی یک نمونه غیرسرطانی تعیین می‌شود. در حال حاضر در هنگام تعریف این جمعیت از دو نوع جهش به طور معمول استفاده می‌شود: جهش‌های ساده بدنی‌های متشکل از تعویض‌ها و درج / حذف کوچک (ایندل) و \gls{cna} حاصل از تغییرات ساختاری بزرگتر. مشاهده انواع جهش‌های دیگر، مانند مجموعه گسترده‌ای از \lr{SV}‌ها که شامل بازآرایی هستند، مشاهده آنها دشوارتر است و روش‌های شناسایی آنها در مراحل اولیه رشد است.


به طور متوسط، حتی در شرایط ایده آل، هر سلول در هر بخش یک جهش پیدا می‌کند \cite{behjati2014genome}، به همین ترتیب، بیشتر سلول‌های تومور ژنوتیپ منحصر به فردی خواهند داشت. بنابراین، به طور دقیق، اکثر سلولهای تومور می‌توانند به طور بالقوه نمایانگر زیرجمعیت منحصر به فرد خود باشند. با این حال، به طور عملی، جهش‌هایی که مختص سلول‌های منفرد است یا فقط تعداد کمی از سلول‌ها آنها را به اشتراک می‌گذارد، در حین فراخوانی نوع شناسایی نمی‌شوند. بعلاوه، سلول‌هایی که بخش عمده‌ای از جهش‌های خود را به اشتراک می‌گذارند، خصوصاً جهش‌های راننده، صفات مشابهی دارند. به همین ترتیب، من قرارداد گسترده‌ای را اتخاذ کرده و یک زیر جمعیت را به عنوان تمام سلول‌هایی که دارای زیر مجموعه یکسان جهش‌های بدنی در هنگام فراخوانی نوع هستند، تعریف می‌کنم.


یک گام مهم در بازسازی زیر کلونال محاسبه شیوع سلولی تبارهای زیر کلونال و سپس، در نهایت، زیرجمعیت‌های سرطانی است. شیوع سلولی یک زیرجمعیت، نسبت سلول‌های نمونه توالی شده متعلق به آن است. غالباً، شیوع سلولی با تقسیم بر خلوص نمونه، یعنی نسبت سلولهای سرطانی در نمونه، به بخش سلولهای سرطانی، نسبت سلولهای سرطانی، تبدیل می‌شود. هر سلول دقیقاً به یک زیرمجموعه تعلق دارد، بنابراین این شیوع باید در یک جمع باشد. به طور کلی، سلول‌های غیر سرطانی در یک زیرمجموعه واحد قرار می‌گیرند. با این حال، از آنجا که جهش‌ها اغلب در زیرجمعیت‌های متعدد وجود دارند، شیوع سلولی بسیاری از زیرجمعیت‌ها را نمی‌توان مستقیماً از جهش‌های آن استنباط کرد. برای پرداختن به این موضوع، ما یک نسب زیر کلونال برای یک جهش به عنوان مجموعه زیرجمعیت‌هایی که در آن وجود دارد، تعریف می‌کنیم. به طور رسمی، \gls{ancestry}‌های زیر کلونال از زیر جمعیت بنیانگذار تشکیل می‌شود (جایی که جهش برای اولین بار ظاهر می‌شود) و همه زیرجمعیت‌های بعدی آن (که وراثت جهش) علاوه بر جهش‌های خاص خود، این زیرمجموعه‌های فرزندی حاوی تمام جهش‌های موجود در نژاد تعریف کننده زیر جمعیت هستند (به جز در صورت حذف محل منبع جهش، برای جزئیات بیشتر به فصل 3 مراجعه کنید). نسب مربوط به یک زیر درخت (یا کلاد) از درخت کلون تومور است. شیوع سلولی یک تبار مجموع شیوع سلولی زیرجمعیت‌هایی است که متعلق به آن تبار هستند. از آنجا که سلول‌ها می‌توانند در چندین نژاد زیرکلونال وجود داشته باشند، شیوع نسب در یک جمع نیست.



شکل \ref{fig:ch_lr:tumor_clone_tree} تصویری از یک درخت کلون نمونه را ارائه می‌دهد. گره‌های موجود در درخت، همانطور که در بالا تعریف شد، نشان دهنده زیر جمعیت است. فلش‌ها از جمعیت والدین به سمت فرزندانشان هدایت می‌شوند. دودمانهای زیر کلونال به صورت مستطیل نشان داده می‌شوند و با توجه به زیرمجموعه بنیادی آنها که در ریشه تیغه یافت می‌شوند، رنگی هستند.


\begin{figure}[!ht]
	\centerline{\includegraphics[width=7cm]{chaps/lr/tumor_clone_tree}}
	\caption{درخت کلون تومور}
	\label{fig:ch_lr:tumor_clone_tree}
\end{figure}




\section{تغییرات تعداد کپی}

بیشتر ژنوم انسان دیپلوئید است، به این معنی که دو نسخه از توالی \gls{dna} ما در سلول‌های ما وجود دارد، یکی از پدر و دیگری از مادر. تغییرات شماره کپی این تغییر را می‌دهند، یا با تغییر در تعداد نسخه‌ها (مثلاً از طریق تکثیر کل ژنوم)، نسبت کپی‌های مادر به پدر (مثلاً از دست دادن خنثی هتروزیگوزیته در تعداد کپی‌ها، جایی که برای همان منطقه یک ژنوم والدین تکثیر می‌شود و دیگری حذف شده است) یا هر دو (به عنوان مثال کپی کروموزوم مادر). بیشتر این تغییرات (به استثنای تکثیر کل ژنوم) دامنه محدودی از ژنوم را تحت تأثیر قرار می‌دهد، اما می‌تواند از تأثیر یک ژن تا یک کروموزوم کامل باشد. این بخش از ژنوم تغییر یافته به عنوان یک بخش شناخته می‌شود.


تغییرات شماره کپی می‌توانند تعداد کپی کل یک بخش و / یا تعداد نسبی نسبی دو کروموزوم والدین را تغییر دهند. هر یک از این تغییرات توسط توالی‌یابی ژنومی هسته قابل تشخیص است. تغییر در تعداد کپی کل یک بخش را می‌توان تشخیص داد زیرا نسبت خواندن آن نقشه به آن بخش بین خط جوانه زنی و نمونه تومور متفاوت خواهد بود. بخش از یک قطعه نسبت ورود خوانده شده است که به یک قطعه در یک نمونه غیر سرطانی ترسیم شده است به نسبت خوانده شده که به یک بخش در یک نمونه سرطانی ترسیم شده است. از نسبت نسبت‌ها برای محاسبه این واقعیت استفاده می‌شود که تعداد کل قرائت‌ها اغلب بین توالی‌یابی سرطانی و غیرسرطانی متفاوت است، در مناطق مختلف ژنوم عمق خواندن بیشتر یا پایین‌تر ناشی از محتوای \lr{GC} یا نقشه برداری وجود دارد و تردستی یک تومور با بافت طبیعی متفاوت است. تکرر یک ژنوم، میانگین تعداد کپی از هر کروموزوم است که برای طول کروموزوم نرمال می‌شود.


با تغییر در کسر آلل می‌توان عدم تعادل در تعداد نسخه‌های مادری و پدری این بخش را تشخیص داد. در مناطق دیپلوئید ژنوم‌ها، اگر یک بازه بین کپی‌های مادر و پدر متفاوت باشد، موقعیت \gls{heterozygous} نامیده می‌شود. جهش‌های تک پایه، خط جوانه زنی همچنین به عنوان چند شکلی تک هسته‌ای نامیده می‌شوند. وقتی یک ژنوم توالی‌یابی شود، حدود نیمی از قرائت آن مکان \gls{heterozygous} حاوی هر یک از بازها خواهد بود، در نتیجه کسر آلل 50 است. این امر تا زمانی که نسبتی برابر با نسخه‌های مادرانه و پدری وجود داشته باشد، صادق خواهد بود. اگر این نسبت تغییر کند، کسر آلل  تمام \gls{polymorphism} تک هسته‌ای در بخش آسیب دیده تغییر می‌کند. \gls{polymorphism} تک هسته‌ای \gls{heterozygous} به طور متوسط هر 1500 باز \cite{chen2012personal} رخ می‌دهد و بنابراین برای بخشهای طولانی بسیاری از \gls{polymorphism} تک هسته ایی \gls{heterozygous} تحت تأثیر قرار می‌گیرند. توزیع کسر آلل \lr{S} تمام \gls{polymorphism} تک هسته‌ای در بخش، حالت دوگانه‌ای پیدا می‌کند که هر حالت نشان دهنده نسبت نسخه‌های آن بخش از هر والد است.

\subsection{روش‌های مطالعه}

فراخوانی \lr{CNA} چالش برانگیز است زیرا با مشاهده مستقل هر بخش، مسئله هنوز مشخص نشده است. حتی با فرض اینکه هر بخش فقط توسط یک \lr{CNA} تحت تأثیر قرار گیرد، \lr{CNA} موسوم به سه پارامتر (نسبت سلولهای حاوی \lr{CNA}، تعداد کپی‌های مادر و تعداد کپی‌های پدری) وجود دارد و فقط دو مشاهده برای توضیح وجود دارد.
همه روش‌ها با فرض اینکه تعداد کمی از نژادهای زیرکلونال مسئول بیشتر یا تمام تغییرات شماره کپی هستند، این ابهام را برطرف می‌کنند. روشی که توسط الگوریتم باتنبرگ \cite{nik2012life} به کار رفته است، به بیشتر تغییرات شماره کپی وابسته به یک نژاد زیر کلونال منفرد و شایع به نام \gls{lineage} کلونال متکی است. تحت این روش، شیوع این تبار، همراه با تعداد کپی اصلی و جزئی در تمام تغییرات تعداد کپی کلونال، می‌تواند با یک فرآیند دو مرحله‌ای تخمین زده شود. در گام اول، این روش با فرض شیوع نژاد کلون $f_c$  آغاز می‌شود. شیوع تبار کلونال در بیشتر موارد با خلوص نمونه تومور برابر است. با توجه به شیوع کلونال، هر بخش پس از آن فقط دو متغیر برای توضیح دارد (تعداد کپی بزرگ و جزئی). از آنجا که هر بخش دارای دو مشاهدات است، اکنون مسئله هنوز به درستی تعیین نشده است و بهترین کپی اصلی و مینور متناسب است. سپس، ترکیب کلی مقدار $\Phi_c$  فرض شده با ترکیب مناسب در تمام بخش‌ها تعیین می‌شود. الگوریتم با بهینه‌سازی این تناسب بهترین مقدار $\Phi_c$  را انتخاب می‌کند. سپس برای هر بخش، شماره کپی اصلی و جزئی با بهینه سازی متناسب بودن قطعه با بهترین مقدار $\Phi_c$   انتخاب می‌شود. این روش فرض می‌کند که تمام تغییرات شماره کپی به نژاد کلونال تعلق دارند، که همیشه درست نیست. در مرحله بعدی، بخشهایی که حاوی تغییرات تعداد کپیتحت کلونال هستند با جستجوی بخشهایی با اطلاعات مناسب ضعیف با استفاده از $\Phi_c$   استنباط شده مشخص می‌شوند. در این بخش‌ها، روش به طور همزمان و مستقل از هر بخش دیگر، عدد $\Phi_i$ و عدد کپی بزرگ و جزئی را استنباط می‌کند.


از آنجا که سه متغیر وجود دارد و تنها دو مشاهده وجود دارد، راه حل‌های بسیاری با تناسب داده برابر وجود دارد که از نظر زیست شناختی برای این تغییرات تعداد کپی زیر کلونال قابل قبول است. این ابهام با انتخاب راه حلی که نزدیکترین شماره به شماره نسخه طبیعی است برطرف می‌شود، اما تعدادی از موارد متداول وجود دارد که این ابتکار عمل ناموفق است. سپس این روش‌ها انتساب تغییرات تعداد کپی زیرکلونال به دودمان و تمام استنباط‌های فیلوژنتیک را برای روش‌های پایین دست رها می‌کنند.

یکی روش دیگر برای تشخیص این تعداد کپی‌ها و تغییرات آن‌ها \lr{aCGH}\LTRfootnote{array-based Comparative Genomic Hybridization} می‌باشد \cite{butler2008array}. در این روش نمونه‌های \gls{dna} را به همراه نمونه‌ای از یک موجود سالم و طبیعی با رنگ‌های فلئورسنت مختلف برچسب‌گذاری می‌کنند. سپس هرکدام از این‌ها با یک \gls{dna} به نام \lr{Cot1} (نمونه‌ای که قسمت‌های تکراری ژنوم در آن مسدود شده است) که برچسب‌گذاری نشده است ترکیب می‌شوند. هرچه که قسمت‌های تکراری بیشتری بر روی نمونه‌های اولیه وجود داشته باشد به این نمونه بدون برچسب اتصال پیدا می‌کنند و در نتیجه آن شدت نورهای متفاوتی از رنگ‌های فلئورسنت ضمیمه شده به آن‌ها ساطع می‌شود. این اختلاف شدت رنگ‌ها در واقع تابعی از میزان تغییرات کپی قسمت‌های تکراری ژنونم بین نمونه مورد مطالعه و نمونه مرجع خواهد بود. بنابرین با تغییراتی در آن‌ها و قرار دادنشان بر روی آرایه‌ای از کلون‌های ژنومی از آن‌ها با ابزارهای دقیق تصویربرداری می‌کنند و سپس با نرم‌افزارهایی به آنالیز این تصاویر می‌پردازند تا با مقایسه شدت رنگ‌ها بتوانند نسبت تعداد کپی‌های نمونه مورد مطالعه و تغییرات بوجود آمده در آن‌ها را با نمونه مرجع در هر قسمت از برش‌های ژنوم بدست آوردند.

رویکرد عمده دیگر این است که فرض کنیم همه تغییرات شماره کپی از تعداد کمی تبار زیر کلونال به وجود می‌آیند. الگوریتم‌هایی که از این روش استفاده می‌کنند به طور مشترک شیوع این نژادها و تعداد کپی بزرگ و جزئی را برای هر بخش استنتاج می‌کنند (به عنوان مثال \lr{THetA}\cite{zhu2011metabolic, vander2009understanding} و \lr{TITAN}). تعداد دودمانهای زیر کلونال معمولاً با استفاده از احتمال جریمه شده‌ای مانند معیار اطلاعات بیزی (\lr{BIC}) یا انواع \lr{BIC} تعیین می‌شود (به عنوان مثال \lr{THetA} از \lr{BIC} اصلاح شده با پارامتر مقیاس گذاری استفاده می‌کند \cite{zhu2011metabolic}). بنابراین این روش‌ها هم تغییرات شماره کپی را فراخوانی می‌کنند و هم آنها را به دودمان‌های زیرکلونال اختصاص می‌دهند. هیچ روش موجود این دودمان‌ها را در یک درخت فیلوژنتیک قرار نمی‌دهد.



\section{جهش‌های ساده بدنی}

جهش‌های ساده بدنی جهش‌های کوچکی هستند که می‌توانند مستقیماً از طریق توالی‌یابی و نسبت کروموزوم‌های موجود در نمونه حاوی آنها از تعداد قرائت‌های حاوی جهش و تعداد کل خوانده‌ها در آن مکان، مشاهده شوند. نسبت قرائت حاوی جهش به کل قرائت به عنوان \lr{VAF} جهش شناخته می‌شود. جهش‌های ساده بدنی‌ها معمولاً با بررسی مشترک ترازها و یک نمونه غیر‌سرطانی خوانده می‌شوند. این استنباط مشترک برای جداسازی انواع بدنی و ژرمینال مورد نیاز است.

این فرایند به دلیل انواع مختلف خطاها و تعصبات که در داده‌های \lr{NGS} وجود دارد، دشوار می‌شود\cite{friedl2010plasticity}. یک مشکل اساسی در تشخیص جهش‌های ساده بدنی این است که به نظر می‌رسد خطاهای توالی جهش‌های ساده بدنی شیوع کمی دارند. به طور خاص، در  \lr{Illumina Hiseq2000}  که به طور گسترده استفاده می‌شود، از هر 1000 پایه یکی از آنها دارای یک خطا است (به طور معمول یک تعویض) \cite{sabeh2009protease}. به همین ترتیب، در طول سه میلیارد پایه ژنوم انسانی، یک احتمال غیر قابل اغماض وجود دارد که در بعضی موقعیت‌ها، چندین بار خواندن دقیقاً شامل خطای توالی دقیقاً در همان موقعیت‌ها است. به نظر می‌رسد این خطاها شیوع کم جهش‌های ساده بدنی دارند. تمایز بین این خطاها و شیوع کم واقعی جهش‌های ساده بدنی‌ها شامل یک معامله بین حساسیت و ویژگی و در حالت ایده آل، یک مدل نویز بسیار دقیق است. حل این مشکل امتداد طبیعی کار گسترده‌ای است که در زمینه فراخوانی جهش‌های جوانه‌زنی انجام شده است و الگوریتم‌های زیادی برای انجام این کار وجود دارد (به عنوان مثال \cite{friedl2010plasticity, demicheli2008effects})

\section{توالی‌یابی سلول منفرد}

تکنیک توالی‌یابی تک-سلولی به فرآیندهای توالی‌یابی ژنوم یا \gls{transcriptome} یک تک سلول اشاره می‌کند، به طوری که نتیجه آن حصول به اطلاعات ژنوم، \gls{transcriptome} یا هر \lr{multi-omics} باشد که به منظور آشکارسازی تفاوت‌های جمعیتی سلولی و روابط تکاملی سلولی مورد استفاده قرار می‌گیرند.
روش‌های توالی‌یابی سنتی تنها می‌توانند به اطلاعاتی کلی در مورد این سلول‌ها برسند بطوری که این اطلاعات برابر با اطلاعاتی کلی و به نحوی برآیندی از یه زیر جمعیت کوچک متشکل از بسیارها تک سلول است و در نتیجه این روش‌ها قادر به آنالیز و بررسی تک نمونه‌ها و یا حتی زیرجمعیت‌های کوچک که همراه با  ناهمگنی در سلول‌های آن هستند، نیست. اما در مقایسه با این روش‌های سنتی، توالی‌یابی تک‌سلولی که روشی نوین در این حوزه است، قادر به تشخیص این ناهمگونی‌ها در میان تک سلول‌ها \cite{wen2018boosting}، \gls{distinguish} یک دسته کوچکی از سلول‌های متفاوت و \gls{delineate} نقشه سلولی است که در سال 2013 به نام \lr{Nature Methods} در یک رویداد سالانه تکنولوژی نام‌گذاری شد \cite{pennisi2012single}. 
با این حال پیش‌تر تعیین توالی تک سلولی به دلیل هزینه‌های زیاد، استفاده گسترده از آن را محدود کرد. اما با پیشرفت تحقیقات، بسیاری از روش‌های توالی‌یابی تک سلولی جدید ایجاد شد که آستانه هزینه آن را کاهش داد. امروزه فناوری توالی‌یابی تک سلولی به طور فزآینده ای در زمینه‌های مختلفی مورد استفاده قرار می‌گیرد که بکارگیری استفاده از این تکنیک‌ها، اهمیت آن را در تحقیقات اساسی و بالینی روشن می‌کند. 

\subsection{خطاهای توالی‌یابی سلول منفرد}
اگرچه این روش با مزایای بسیاری همراه است اما مشکلات مربوط به خود را دارد که برای نمونه می‌توان به حساسیت بسیار بالا به کیفیت نمونه‌های اولیه در آن اشاره کرد. همچنین به علت نیاز به تکثیر هرکدام از سلول‌ها تا تعداد قابل قبول، خطاهای متفاوتی در این بین می‌تواند بوجود آید که نتیجه نهایی را همراه با خطا کند که از جمله‌ آن‌ها می‌توان به تکثیر نا متعادل در قسمت‌های مختلف ژنوم و بایاس سیستماتیک در تکثیر نواحی با \lr{GC\%} مختلف اشاره کرد. در ادامه به بررسی برخی از نتایج این فرآیند و خطاهای پس از تکثیر در حین توالی‌یابی می‌پردازیم.

\subsubsection{عدم و یا حداقلی \gls{coverage}}
اگر در توالی‌یابی نتوان تمام ژنوم را پوشش داد در این صورت قسمت‌هایی از ژنوم هستند که دیده نشده‌اند و در نتیجه نمی‌توانیم آن قسمت‌ها را با ژنوم مرجع مقایسه کنیم و کشف جهش انجام دهیم. در این حالت مشخص است که هرچیزی برای آن نواحی درنظر بگیریم با خطا همراه خواهد بود. همچنین در برخی نواحی نیز ممکن است میزان پوشش‌دهی حداقل باشد. یعنی بر تکه‌های مختلف ژنوم از نمونه مورد مطالعه به فرض تنها یک خوانش داشته باشیم. در این حالت تمام خطای آن خوانش به کل نتیجه برای آن قسمت از ژنوم در تصمیم‌گیری منتقل خواهد شد \cite{chan2017gene}.

\subsubsection{خطای غیریکنواختی پوشش‌دهی}
حالت دیگر برای بوجود آمدن خطا در توالی‌یابی به نحوه پوشش‌دهی خوانش‌ها از قسمت‌های مختلف ژنوم بازمی‌گردد. در حالتی که خوانش‌ها و پوشش‌دهی‌ها به صورت غیر یکنواخت از ژنوم باشند اما در هنگام توالی‌یابی با فرض یکنواختی آن‌ها انتصابات به ژنوم مرجع انجام شود. در این حالت نیز به علت غیریکنواختی پوشش‌دهی ممکن است خروجی توالی‌یابی و کشف یا عدم کشف جهش‌ها متفاوت از حقیقت ماجرا و همراه با خطا باشد \cite{garvin2015interactive, lemey2009phylogenetic}.

\subsubsection{\gls{allelecdropout}}
اگرچه روش‌های تعیین توالی با بازدهی بالا \cite{hugo2007epithelial} ارزان هستند، اما تحت تاثیر مقدار بایاس هستند و مارکرهای ژنتیکی‌ای تولید می‌کنند که تقریباً به طور تصادفی در کل ژنوم تقسیم می‌شوند. این روش‌ها با موفقیت در \gls{mapping} صفات \cite{nowell1976clonal, greaves2012clonal}، ساخت نقشه پیوندی \cite{sakr1993frequency, fearon1990genetic}،  اسکن انتخاب  \cite{dentro2018portraits, waclaw2015spatial}،  و برآورد تنوع ژنتیکی \cite{de2006clonal} استفاده شده است. یکی از این روش‌ها، تعیین ژنوتیپ براساس توالی \cite{anderson2011genetic} (\lr{GBS}) است. در \lr{GBS}، هدف توالی‌یابی فقط با اتصال آداپتورهای توالی به محل‌های برش آنزیم محدود کننده، به کمتر از $5\%$ از ژنوم کاهش می‌یابد (شکل \ref{fig:ch_lr:mtsd}).  قرائت \lr{GBS} همچنین می‌تواند به صورت کانکت‌های کوتاه مونتاژ شود، که بدون نیاز به توالی ژنوم فراخوانی یک نوع تغییر تک هسته‌ای (تغییرات تک نوکلئوتیدی) را امکان پذیر می‌کند \cite{hanahan2000hallmarks}. از این رو، \lr{GBS} یک روش محبوب در سیستم‌های غیر مدلی است که به طور معمول فاقد منابعی مانند مجموعه ژنوم و ریزآرایه‌ها است.

بر خلاف توالی‌یابی کل ژنوم \lr{(WGS)}، \lr{GBS} مستعد ابتلا به خطاهای مختلف تماس به دلیل محدودیت چندشکلی‌های سایت  است (کاهش آللیک). کاهش آللیک در \lr{GBS} می‌تواند برنامه‌هایی را که به فراخوانی دقیق تغییرات نادر، از جمله تخمین طیف فرکانس سایت در ژنتیک جمعیت متکی هستند، را دچار اختلال کند. یک رویکرد آماری سیستماتیک برای تشخیص کاهش آللیک در داده‌های توالی \lr{GBS}، اجرا شده و  در بسته نرم افزاری منبع باز \lr{GBStools} وجود دارد.  این روش مبتنی بر این واقعیت است که کاهش آللیک متناسب با تعداد آللهای سایت محدود کننده بدون برش که در آنجا حمل می‌کند، میزان خوانش نمونه را در یک سایت خاص کاهش می‌دهد. بنابراین \lr{GBStools} پوشش هر نمونه را در یک سایت خاص به عنوان یک متغیر تصادفی پواسون مورد استفاده قرار می‌دهد که از توزیع با میانگین \lr{$\lambda$} (آللیک‌های بدون برش صفر)، توزیع با میانگین ½\lr{$\lambda$} (یک آللیک بدون برش)، یا با میانگین صفر (دو آللیک بدون برش). \lr{GBStools} حداکثر احتمال پارامتر \lr{$\lambda$} را با استفاده از تعداد واقعی آللیک‌های بدون برش در هر نمونه که به عنوان متغیرهای نهفته (مشاهده نشده) در نظر رفته می‌شود و از طریق  حداکثر رساندن  مقدار چشم انتظاری \lr{(EM)}، محاسبه می‌کند . از مقادیر مورد انتظار این متغیرهای نهفته می‌توان برای تخمین اینکه کدام نمونه ها یک آللیک بدون برش دارند استفاده کرد. به طور همزمان، \lr{GBStools} فرکانس سایت آلل‌های \lr{SNP} مرجع قابل مشاهده و جایگزین، \lr{$\varphi_1$} و  \lr{$\varphi_2$}  ، و آللیک بدون برش، \lr{$\varphi_3$} ، که در آن  \lr{$\varphi_1$+$\varphi_2$+$\varphi_3$=1}   برآورد می‌کند و در نهایت، آزمون نسبت احتمال با مقایسه فرضیه صفر  \lr{$\varphi_3$ = 0} با فرضیه \lr{$\varphi_3$> 0} جایگزین می‌کند. \lr{GBStools}  در اجرای فعلی خود نمی تواند ژنوتیپ‌های واقعی پنهان شده توسط کاهش آللیک را استنباط کند، اما می‌توان با فیلتر کردن سایت‌هایی که نسبت احتمال آنها زیاد است خطاها را حذف کند.

\begin{figure}[!ht]
	\centerline{\includegraphics[width=\textwidth]{chaps/lr/mtsd}}
	\caption{نمایی از تطابق ژنتیکی}
	\label{fig:ch_lr:mtsd}
\end{figure}

در شکل بالا، آلل \lr{BpuEI} بدون برش ناشی از \lr{SNP rs72926658} با برچسب "-`` و آلل برش با "+`` برچسب گذاری شده است. آلل "-`` در هاپلوتیپ با آلل \lr{G} مشتق شده بوجود آمده و باعث شده تا برخی از آلل‌های \lr{G} توسط \lr{GBS} قابل مشاهده نباشند. نمونه‌های نشان داده شده دارای سه دیپلوتیپ \gls{heterozygous} است. نتایج توالی با پیش‌بینی‌ها مطابقت داشت و نمونه \lr{NA18505} به اشتباه هموزیگوت نامیده می‌شد، اما انتظار می‌رود تعداد آلل‌های کاهشی محاسبه‌شده توسط \lr{GBStools (0.958)} با تعداد واقعی (1) مطابقت داشته باشد، و آن را به عنوان یک تماس اشتباه احتمالی مشخص کند.

\subsubsection{خطای \gls{falsepositive} و \gls{falsenegative}}
در نهایت با توجه به مواردی که در بخش‌های قبل بیان شد ممکن است داده‌های نهایی که به عنوان جهش‌ها قرار است به عنوان خروجی گزارش باشند با حقیقت ماجرا متفاوت باشند. در این حالت اگر بخواهیم نمونه‌های مختلف را به همراه جهش‌هایی که داشته‌اند نمایش دهیم می‌توان آن‌ها را در یک ماتریس قرار داد که ستون‌ها و سطرها هر کدام نماینده سلول‌ها و جهش‌ها خواهند بود و درایه‌های این ماتریس نیز مقادیر $1$ و $0$ به خود می‌گیرند که به تریتیب به معنی وجود و عدم وجود آن جهش در آن سلول است. در نتیجه خطاهایی که به علت اشتباه در روش‌های تکثیر و نمونه‌گیری، خطای محاسباتی و ... بوجود می‌آیند در چنین حالتی خود را به صورت مقادیر دودویی متفاوت با مقدار واقعی نشان می‌دهند. اگر نتیجه خطا باعث به اشتباه $1$ شدن باشد آن را \gls{falsepositive} و اگر باعث به اشتباه $0$ شدن باشد آن را \gls{falsenegative} می‌گوییم.

\section{درخت فیلوژنتیک}
درخت فیلوژنتیک (همچنین فیلوژنی، تبارزایشی یا درخت تکاملی\LTRfootnote{Evolutionary tree}) یک نمودار شاخه‌ای یا درختی است که روابط تکاملی بین ژن‌ها، گونه‌های مختلف بیولوژیکی یا موجودات دیگر را بر اساس شباهت‌ها و تفاوت‌های ویژگی‌های فیزیکی یا ژنتیکی آنها نشان می‌دهد \cite{davis2016computing}. در مسئله پیش روی این پایان‌نامه قرار است تا به استنتاج درخت فیلوژنی پرداخته شود که در آن انشعاب شاخه‌ها، دودمان‌ها را در طی گذر زمان نمایش می‌دهد. نقطه‌هایی را که در آنها دودمان‌ها واگرا می‌شوند گره می‌نامند که هر گره نشان‌دهنده جد مشترکی برای فرزندان آن گره و گونه‌های واگرا شده در گره می‌باشد. انتهای شاخه‌ها بیان‌گر گونه‌هایی است که امروزه ممکن است زنده باشند و یا حتی منقرض شده باشند. ریشه درخت فیلوژنتیک نیز نشان دهنده قدیمی‌ترین جد مشترک همه گروه‌های نشان داده شده روی درخت است. در برخی حالات نیز طول اتصالات نشان‌دهنده‌ای از گذر زمان است. همچنین اگر دو گونه خاص در درخت، وابستگی بیشتری داشته باشند آنگاه اجداد مشترک بیشتری نیز خواهند داشت و بالعکس \cite{gori2016clustering}. در نهایت می‌توان گفت هر گره از این درخت بیانگر یک ژن از نمونه‌های سلول‌های مختلف مورد بررسی خواهد بود، به طوری که ساختار این ژن‌ها در این درخت مشخص کننده تقدم و تاخر بین جهش‌هایی می‌باشد که در طی فرآیند تکاملی درون تومور برای سلول‌های درون آن اتفاق افتاده است.

\section{مقدمه‌ای بر مدل‌سازی احتمالی}

وظیفه اصلی یادگیری ماشین، یادگیری از داده‌ها است، کاری که به عنوان استنباط شناخته می‌شود. برای یادگیری از داده‌ها، باید فرضیاتی را مطرح کرد. توصیف رسمی فرضیات صورت گرفته به عنوان یک مدل ذکر می‌شود. یک مدل احتمالی مفروضات ارائه شده را تعریف می‌کند که اطلاعات آموخته شده را با استفاده از متغیرهای تصادفی و توزیع‌های احتمال به داده‌های مشاهده شده پیوند می‌دهد. توزیع‌های احتمال توابع ریاضی هستند که یک رویداد را ورودی می‌کنند و احتمال آن واقعه را بیرون می‌آورند. توزیع احتمال می‌تواند تابعی بیش از واقعه باشد و این متغیرهای اضافی به عنوان پارامترهای توزیع شناخته می‌شوند\cite{hanahan2000hallmarks}. 
رویکرد بیزی در یادگیری ماشین شامل استنباط احتمالی مقادیر پارامترهای منوط به مشاهدات است \cite{hanahan2011hallmarks}. چهار مولفه دارد:

\begin{itemize}
	\item 	احتمال: احتمال مشاهده داده‌ها است، مشروط به تنظیم پارامتر \lr{ P(data | parameters)} 
	\item 	پارامترهای احتمال
	\item	پارامترهای قبلی 
	\item داده‌های مشاهده شده
\end{itemize}
پارامترها خود مجموعه‌ای از متغیرهای تصادفی هستند که از توزیع قبلی \lr{P} (پارامترها) گرفته شده اند، که باورهای ما را در مورد احتمال حالت‌های مختلف پارامتر در غیاب مشاهده مشاهده می‌کند. این اصطلاحات با استفاده از قانون بیز با هم ترکیب می‌شوند:
\begin{itemize}
	\item \lr{P(parameters|data) = P(data|parameters) $*$ P(parameters) $/$ P(data)}
	\item \lr{Posterior $\propto$ likelihood  $*$  prior}
\end{itemize}
پس زمینه توزیع پارامترهای مشروط به مشاهده داده‌ها است و خروجی اصلی استنتاج بیزی است. از توزیع پسین می‌توان برای انجام کارهایی مانند پیش‌بینی مشاهدات آینده استفاده کرد.


\subsection{\gls{markovchainmontecarlo}}

برای انجام استنتاج \gls{bayesian}، ما اغلب می‌خواهیم در توزیع پسین ادغام شده، پیش‌بینی کنیم یا خلاصه‌هایی پیدا کنیم، به عنوان مثال میانگین پارامتر پسین. به طور کلی، انجام چنین ادغامی (جمع بندی در مورد متغیرهای گسسته) از نظر تحلیلی غیرقابل حل است. با این حال، می‌توان چنین ادغام‌هایی را با استفاده از نمونه‌هایی که از قسمت پسین ترسیم شده‌اند تقریبی داد:
\begin{equation}
	E[f]=\int f(x) p(x) d x \approx 1 / N \sum_{1 . . N} f\left(x_{i}\right)
\end{equation}
که در آن $x_i$  نمونه $i$ از $p(x)$ و $p(x)$  و $f(x)$ به ترتیب توزیع و عملکرد مورد نظر ما است. به ندرت می‌توان مستقیماً از توزیع پسین نمونه برداری کرد. برای تولید موثر نمونه‌ها از توزیع، حتی در ابعاد بالا، می‌توان از تکنیک زنجیره ماکوف مونت کارلو استفاده کرد. زنجیره ماکوف مونت کارلو یک زنجیره مارکوف می‌سازد که در آن توزیع تعادل توزیع پسین است. سپس مقادیر زنجیره می‌تواند به عنوان نمونه از پسین با توجه به همگرایی کافی به توزیع تعادل مورد استفاده قرار گیرد. برای انجام زنجیره ماکوف مونت کارلو، تاز زمانی که بتوان \lr{$p \propto p(x)$ } را محاسبه کرد، نیازی به محاسبه $p(x)$  نیست. این زنجیره ماکوف مونت کارلو را قادر می‌سازد تا از محاسبه ثابت‌های نرمال سازی، که اغلب غیرقابل حل هستند، خودداری کند.
یک زنجیره مارکوف به عنوان یک سری متغیرهای تصادفی تعریف می‌شود که دارای ویژگی استقلال شرطی زیر هستند:
\begin{equation}
	p\left(z^{N+1} \mid z^{1} . . z^{N}\right)=p\left(z^{N+1} \mid z^{N}\right)
\end{equation}
نمونه‌ای از الگوریتم زنجیره ماکوف مونت کارلو الگوریتم \lr{Metropolis-Hastings (MH)} است \cite{hastings1970monte}. الگوریتم \lr{MH}  از حالت دلخواه   $Z^t$ شروع می‌شود. سپس یک حالت پیشنهادی $z$  از توزیع پروپوزال \lr{$q(z | z^t)$} ترسیم می‌شود. این حالت پیشنهادی $z$   با احتمال زیر پذیرفته می‌شود:
\begin{equation}
	\min \left(1, \hat{p}\left(z^{*}\right) q\left(z^{t} \mid z^{*}\right) / \hat{p}\left(z^{t}\right) q\left(z^{*} \mid z^{t}\right)\right)
\end{equation}
می توان نشان داد که الگوریتم MH تعادل دقیق را برآورده می‌کند و از این رو،$p(x)$ توزیع تعادل است \cite{bishop2006pattern}. در حالی که توازن دقیق برای اثبات اینکه در محدوده نمونه‌های بی‌نهایت زنجیره به توزیع مورد نظر همگراست کافی است، اما در عمل فقط تعداد محدودی از نمونه‌ها را می‌توان ترسیم کرد. واضح است که نمونه‌های ابتدای زنجیره، که از یک مکان دلخواه در فضای حالت شروع می‌شوند، بعید است از توزیع تعادل باشد. این نمونه‌ها به عنوان نمونه‌های سوختنی کنار گذاشته می‌شوند. هرچه همگرایی زنجیره مارکوف سریعتر باشد، نمونه‌های کمتری باید کنار گذاشته شوند و می‌توان از تعداد بیشتری برای محاسبه انتظارات استفاده کرد. با بررسی اثری از مقادیر مهم پارامتر یا احتمال همگرایی می‌توان نظارت کرد، اما این امر ممکن است چند حالت را از دست بدهد. متأسفانه دانستن اینکه آیا همگرایی حاصل شده است غیرممکن است، فقط گاهی اوقات می‌توان همگرایی را رد کرد \cite{gelman2011inference}. گذشته از همگرایی، یکی دیگر از خصوصیات اصلی یک زنجیره مارکوف میزان اختلاط زنجیره است. با توجه به n نمونه مستقل از توزیع، واریانس میانگین پارامتر برآورد $ \sigma_n $ است که $\sigma$ انحراف استاندارد توزیع خلفی پارامتر است. نمونه‌های گرفته شده از زنجیره مارکوف مستقل نیستند، زیرا به وضعیت فعلی زنجیره بستگی دارند (یعنی فقط از نظر شرطی مستقل هستند). برای تخمین اندازه نمونه موثر یک زنجیره مارکوف، یعنی تعداد نمونه‌های مستقل با همان خطای استاندارد همان زنجیره، می‌توان از معادله زیر استفاده کرد:
\begin{equation}
	E S S=\frac{n}{1+2 \sum_{0}^{\infty} \rho_{j}}
\end{equation}
حاصل جمع بی نهایت محاسبه \lr{ESS} را می‌توان با استفاده از برآوردگر پریودوگرام کوتاه تطبیقی \lr{Sokal} \cite{sokal1997monte} تخمین زد.


\section{\gls{deeplearning} و \gls{reinforcementlearning}}

آنالیز داده‌های بالینی یک حوزه مهم تحقیقاتی در انفورماتیک، علوم کامپیوتر و پزشکی است که توسط محققان شاغل در دانشگاه‌ها، صنعت و مراکز بالینی انجام می‌شود. یکی از بزرگ‌ترین چالش‌ها در تجزیه و تحلیل داده‌های پزشکی، استخراج و تجزیه و تحلیل داده‌های توالی‌یابی است. در چند سال اخیر روش‌های \gls{machinelearning} انقلابی بزرگ در \gls{computervision} به وجود آورده است که راه‌حل‌های جدید و کارآمدی را درمورد خیلی از مسائل و مشکلات موجود در آنالیز سیگنال‌های دوبعدی که مدت زمان طولانی است حل نشده باقی مانده‌اند معرفی می‌کنند. 

برای اینکه این قدرت بتواند وارد حوزه بایوانفورماتیک شود باید رویکردها و روش‌های اختصاصی‌ای طراحی شوند تا خاص بودن دادگان این حوزه را بتوانند در نظر بگیرند. 
سیستم‌های کامپیوتری هوشمند چندین دهه است که در دنیا جایگاه برجسته‌ای پیدا کرده‌اند. در حال حاضر، به خاطر تکنیک‌های جدید \gls{ai}، قابلیت پردازش کامپیوتری بالا و رشد گسترده استخراج داده‌ها و ذخیره‌سازی دیجیتالی آن‌ها، کاربرد \gls{ai} در حال انتقال به حوزه‌های گوناگون می‌باشد. حوزه بایوانفورماتیک نیز از این قاعده مستثنی نیست و تکنیک‌های هوش مصنوعی در آن به روز به روز بیشتر از گذشته جایگزین روش‌های غیرهوشمند محاسباتی می‌شوند. 

%در حوزه پزشکی، سیستم‌های \gls{ai} به منظور آشکارسازی بیماری، پیش‌بینی و به عنوان استراتژی پشتیبان در تصمیم‌گیری بالینی در حال توسعه، کاوش و ارزیابی هستند. در زمینه \gls{breastcancer} از \gls{ai} به منظور آشکارسازی زودهنگام و تفسیر \glspl{mammogram} به منظور بهبود غربالگری سرطان پستان و کاهش تشخیص \gls{falsepositive} استفاده می‌شود و این امکان فراهم شده است تا متخصصانی مانند \glspl{radiologist} بتوانند بر اساس میلیون‌ها تصویر از بیماران قبلی که مشخصات مشابهی دارند، تصمیمات آگاهانه‌ای بگیرند. استفاده از \gls{ai} در شیوه‌های تشخیص \gls{breastcancer} به \gls{imagingmodality} و همچنین تفسیر \gls{pathology} نیز گسترش یافته است. \gls{deeplearning} که زیر شاخه‌ای از \gls{machinelearning} می‌باشد یکی از تکنیک‌های \gls{ai} است که در انواع مختلفی از مسائل کلینیکی و پردازش تصاویر پزشکی شامل \gls{detection}/\gls{recognition}، \gls{segmentation} و \gls{computeraideddiagnosis} به کار گرفته می‌شود.

یادگیری عمیق مجموعه‌ای از الگوریتم‌های ماشین است که قادر به مدل‌سازی الگوها به طور مستقیم از داده‌های خام می‌باشد. الگوریتم‌های یادگیری عمیق از مجموعه‌ای از لایه‌های چندگانه با واحدهای پردازنده غیرخطی برای استخراج و تبدیل ویژگی استفاده می‌کنند. هر لایه از خروجی لایه قبل به عنوان ورودی استفاده می‌کند. این مفهوم با بسیاری از روش‌های دیگر یادگیری ماشین که نیاز به استخراج ویژگی دارند متفاوت است. به همین ترتیب این الگوریتم‌ها حتی در مسائلی که دانش بسیار کمی در موردشان وجود دارد، می‌توانند مورد استفاده قرار گیرند. اگرچه در دهه 1990 این الگوریتم‌ها در برخی از مطالعات مورد استفاده قرار گرفته اند، اما در چند سال اخیر شاهد نتایج بسیار چشمگیر این الگوریتم‌ها هستیم. با توجه به وجود داده‌های بیشتر و همچنین قدرت محاسباتی بالا، این روش‌ها در بسیاری از زمینه‌ها توانسته اند به عملکرد انسان یا بهتر از انسان دست یابند\cite{akselrod2017deep}. شبکه‌های عصبی مصنوعی نوع خاصی از مدل‌های یادگیری عمیق هستند.

اما در ادامه به توضیح شبکه‌های عصبی کانولوشنی خواهیم پرداخت. شبکه عصبی کانولوشن نوعی شبکه عصبی است که عمدتا در برنامه های پردازش تصویر استفاده می شود. اما دیگر کاربردهای آن در داده‌های متوالی مانند صدا، سری زمانی و NLP است. که در این پایان‌نامه نیز ما قصد داریم از این ساختار شبکه به عنوان یک ساختار \gls{encoder} در جهت تغییر فضای نمونه‌ها و استخراج ویژگی از آن‌ها برآییم. کانولوشن\LTRfootnote{Convolution} یکی از اجزای اصلی \lr{CNN}\LTRfootnote{Convolutional neural network} است. واژه کانولوشن به ترکیب ریاضی دو تابع برای تولید تابع سوم اشاره دارد. در واقع این عملگر  دو مجموعه اطلاعات را هم ادغام می‌کند. 
\\
\noindent
\textbf{عملیات کانولوشن}
در این عملیات دو تابع که یکی را فیلتر می‌نامیم بر روی قسمتی از داده ورودی(ویژگی) به سایز فیلتر اعمال خواهد شد که نتیجه به صورت رابطه زیر محاسبه می‌شود.
\begin{equation}
	(f*g)[n]=\sum _{m=-k/2}^{k/2}f[n-m]g[m]
\end{equation}
\noindent
همچنین بعد خروجی را پس از یک چرخش می‌توانیم به صورت رابطه‌ای که در ادامه آمده است در نظر بگیریم.
\begin{equation}
	n_{out} = \left[\frac{n_{in}+2p-k}{s}\right]+1
\end{equation}
که در آن $n_{in}$ برابر با تعداد ویژگی‌های ورودی، $n_{out}$ برابر با تعداد ویژگی‌های خروجی،‌ $k$ برابر با سایز فیلتر، $p$ برابر با سایز \lr{padding} و $s$ برابر با سایز \lr{stride} می‌باشد.

\begin{figure}[!ht]
	\centerline{\includegraphics[width=8cm]{chaps/lr/cnn_1d}}
	\caption{نمونه‌ای از کانولوشن ۱ بعدی بر روی داده ۱ بعدی}
	\label{fig:ch_lr:rnn}
\end{figure}
در پیوست \ref{appex:cnn} توضحیات کاملی در خصوص نحوه کارکرد شبکه‌های عصبی کانولوشنی آورده شده است. برای درک بهتر نحوه کارکرد این شبکه‌ها پیوست اشاره شده به توضیح این ساختار در قالب تحلیل داده‌های دو بعدی می‌پردازد که البته در مسئله پیش روی این پایان‌نامه داده‌های ورودی و روابط سادتر به صورت یک‌بعدی خواهد بود.

 \section{شبکه‌های عصبی بازگشتی}
 قبل از آشنا شدن با \glspl{rnn} بهتر است مروری بر مفهوم شبکه عصبی داشته باشیم. شبکه‌های عصبی مجموعه‌ای از الگوریتم‌ها هستند که شباهت نزدیکی به مغز انسان داشته و به منظور تشخیص الگوها طراحی شده‌اند. شبکه‌ی عصبی داده‌های حسی را از طریق ادراک ماشینی ، برچسب زدن یا خوشه بندی ورودی‌های خام تفسیر می‌کند. شبکه می‌تواند الگوهای عددی را شناسایی ‌کند؛ این الگوها بردارهایی هستند که همه‌ی داده‌های دنیای واقعی (تصویر، صدا، متن یا سری‌های زمانی) برای تفسیر باید به شکل آن‌ها درآیند. شبکه‌های عصبی مصنوعی از تعداد زیادی مؤلفه‌ی پردازشی (نورون) تشکیل شده‌اند که اتصالات زیادی بینشان وجود دارد و برای حل یک مسئله با یکدیگر همکاری دارند.
 شبکه‌ی عصبی مصنوعی معمولاً تعداد زیادی پردازشگر دارد که به صورت موازی کار می‌کنند و در ردیف‌هایی کنار هم قرار می‌گیرند. ردیف اول، همچون عصب‌های بینایی انسان در پردازش بصری، اطلاعات ورودی‌های خام را دریافت می‌کند. سپس هر کدام از ردیف‌های بعدی، به جای ورودی خام، خروجی ردیف قبلی را دریافت می‌کنند؛ در پردازش بصری نیز نورون‌هایی که از عصب بینایی فاصله دارند، سیگنال را از نورون‌های نزدیک‌تر می‌گیرند. ردیف آخر خروجی کل سیستم را تولید می‌کند.

\subsection{شبکه عصبی بازگشتی چیست؟}
 شبکه‌ی عصبی بازگشتی شکلی از شبکه‌ی عصبی پیشخور است که یک حافظه‌ی داخلی دارد. شبکه عصبی بازگشتی ذاتاً بازگشتی است، زیرا یک تابع یکسان را برای همه‌ی داده‌های ورودی اجرا می‌کند، اما خروجی داده‌ی (ورودی) فعلی به محاسبات ورودی قبلی بستگی دارد. خروجی بعد از تولید، کپی شده و مجدداً به شبکه‌ی بازگشتی فرستاده می‌شود. این شبکه برای تصمیم‌گیری، هم ورودی فعلی و هم خروجی که از ورودی قبلی آموخته شده را در نظر می‌گیرد.
 شبکه عصبی بازگشتی برخلاف شبکه‌های عصبی پیشخور می‌توانند از حالت (حافظه‌ی) درونی خود برای پردازش دنباله‌هایی از ورودی‌ها استفاده کنند. این خاصیت باعث می‌شود در مسائلی همچون تشخیص دست‌خط زنجیره‌ای یا تشخیص گفتار کاربرد داشته باشند. در سایر شبکه‌های عصبی، ورودی‌ها از یکدیگر مستقل هستند، اما در شبکه عصبی بازگشتی ورودی‌ها به هم مرتبط می‌باشند. به شکل \ref{fig:ch_lr:rnn} توجه کنید،
 \begin{figure}[!ht]
 	\centerline{\includegraphics[width=14cm]{chaps/lr/rnn}}
 	\caption{
 		یک نمونه بازشده \gls{rnn}
 	}
 	\label{fig:ch_lr:rnn}
 \end{figure}
 این شبکه ابتدا $X_0$ را از دنباله‌ی ورودی‌ها گرفته و خروجی $h_0$ را تولید می‌کند که همراه با $X_1$ ورودی گام بعدی محسوب خواهند شد. یعنی $h_0$ و $X_1$ ورودی گام بعدی هستند. به همین صورت $h_1$ بعدی همراه با $X_1$ ورودی گام بعدی خواهند بود. شبکه عصبی بازگشتی بدین طریق می‌تواند هنگام آموزش زمینه را به خاطر داشته باشد.
 فرمول \gls{state} کنونی به صورت رابطه \ref{eq:ch_lr:rnn_cs} خواهد بود که در آن،
 \begin{equation}
 	h_t = f(h_{t-1}, x_t)
 	\label{eq:ch_lr:rnn_cs}
 \end{equation}
 خواهد بود که در آن $h_t$ برابر است با،
 \begin{equation}
 	h_t = \tanh(W_{hh}h_{t-1} + W_{hx}x_t)
 	\label{eq:ch_lr:rnn_ht}
 \end{equation}
 در این فرمول $W$ وزن، $h$ تک‌بردار نهان، $W_hh$ وزن حالت نهان قبلی، $W_{hx}$ وزن حالت ورودی کنونی و $\tanh$ \gls{activationfunction} است که با استفاده از تابعی غیرخطی، خروجی را فشرده می‌کند تا در بازه‌ی $[1, -1]$ جای گیرند. در نهایت \gls{state} خروجی $Y_t$ از طریق رابطه \ref{eq:ch_lr:rnn_hy} بدست می‌آید،
 \begin{equation}
 	y_t = W_{hy}h_t
 	\label{eq:ch_lr:rnn_hy}
 \end{equation}
 که در آن $W_{hy}$ برابر وزن در \gls{state} تولید شده را نشان می‌دهد.
 
 \subsection{مزایای \gls{rnn}}
 شبکه عصبی بازگشتی می‌تواند دنباله‌ای از داده‌ها را به شکلی مدل‌سازی کند که هر نمونه وابسته به نمونه‌های قبلی به نظر برسد. شبکه عصبی بازگشتی را می‌توان با لایه‌های پیچشی نیز به کار برد تا گستره‌ی همسایگی پیکسلی را افزایش داد.
 
 \subsection{معایب \gls{rnn}}
 \begin{itemize}
 	\item گرادیان کاهشی و مشکلات ناشی از آن
 	\item آموزش بسیار دشوار
 	\item ناتوانی در پردازش دنباله‌های طولانی از ورودی در صورت استفاده از \gls{activationfunction}  $\tanh$ یا \lr{ReLU}
 \end{itemize}

\subsection{کاربردهای \gls{rnn}}
\begin{itemize}
	\item شرح نویسی عکس\LTRfootnote{Image Captioning}: شبکه عصبی بازگشتی با تحلیل حالت کنونی عکس، برای شرح نویسی عکس به کار می‌رود
	\item پیش بینی سری‌های زمانی\LTRfootnote{Time Series Prediction}: هر مسئله سری زمانی مانند پیش بینی قیمت یک سهام در یک ماه خاص، با \gls{rnn} قابل انجام است
	\item
	پردازش زبان طبیعی\LTRfootnote{Natural Language Processing}: کاوش متن و تحلیل احساسات می‌تواند با استفاده از \gls{rnn} انجام شود
	\item
	ترجمه ماشینی\LTRfootnote{Machine Translation}: شبکه \gls{rnn} می‌تواند ورودی خود را از یک زبان دریافت و آن را به عنوان خروجی به زبان دیگری ترجمه کند
\end{itemize}
 
\subsection{انواع \gls{rnn}}
\noindent
 به طور کلی 4 نوع شبکه عصبی بازگشتی داریم:\\
 یک به یک (\lr{one to one}) : این نوع شبکه عصبی به عنوان شبکه عصبی وانیلی نیز شناخته می‌شود و برای مسائل یادگیری ماشین که یک ورودی و یک خروجی دارند به کار می‌رود.

 \begin{figure}[!ht]
 	\centering
 	\subfloat[یک به یک]{
 		\centering
 		\includegraphics[width=0.17\textwidth]{chaps/lr/rnn_oto}
 		\label{fig:ch_lr:rnn_oto}
 	}
 	\hfill
 	\subfloat[یک به چند]{
 		\centering
 		\includegraphics[width=0.26\textwidth]{chaps/lr/rnn_otm}
 		\label{fig:ch_lr:rnn_otm}
 	}
 	\hfil
 	\subfloat[چند به یک]{
 		\centering
 		\includegraphics[width=0.26\textwidth]{chaps/lr/rnn_mto}
 		\label{fig:ch_lr:rnn_mto}
 	} 	\hfill
 	\subfloat[چند به چند]{
 		\centering
 		\includegraphics[width=0.26\textwidth]{chaps/lr/rnn_mtm}
 		\label{fig:ch_lr:rnn_mtm}
 	}
 	\caption{ساختار \gls{rnn}}
 	\label{fig:ch_lr:rnn_xtx}
 \end{figure}
 
% 
% \begin{figure}[!ht]
% 	\centerline{\includegraphics[width=4cm]{chaps/lr/rnn_oto}}
% 	\caption{ساختار \gls{rnn} یک به یک}
% 	\label{fig:ch_lr:rnn_oto}
% \end{figure}
%\\
 یک به چند (\lr{one to many}): این شبکه عصبی بازگشتی دارای یک ورودی و چند خروجی است. یک نمونه آن، شرح نویسی عکس است.
% \begin{figure}[!ht]
% 	\centerline{\includegraphics[width=7cm]{chaps/lr/rnn_otm}}
% 	\caption{ساختار \gls{rnn} یک به چند}
% 	\label{fig:ch_lr:rnn_otm}
% \end{figure}
\\

 چند به یک (\lr{many to one}): این نوع از \gls{rnn}، دنباله ایی از ورودی ها را می‌گیرد و یک خروجی تولید می‌کند. تحلیل احساسات مثال خوبی از این نوع شبکه است که یک جمله را به عنوان ورودی می‌گیرد و آن را با احساس مثبت یا منفی طبقه بندی می‌کند.

%
% \begin{figure}[!ht]
% 	\centerline{\includegraphics[width=7cm]{chaps/lr/rnn_mto}}
% 	\caption{ساختار \gls{rnn} چند به یک}
% 	\label{fig:ch_lr:rnn_mto}
% \end{figure}
 
 چند به چند (\lr{many to many}): دنباله ایی از ورودی ها را می‌گیرد و دنباله ایی از خروجی ها را تولید می‌کند. ترجمه ماشینی نمونه ایی از این نوع شبکه است.
%\begin{figure}[!ht]
%	\centerline{\includegraphics[width=7cm]{chaps/lr/rnn_mtm}}
%	\caption{ساختار \gls{rnn} چند به چند}
%	\label{fig:ch_lr:rnn_mtm}
%\end{figure} 

در پیوست \ref{appex:lstm} شبکه‌های حافظه کوتاه مدت بلند به تفضیح توضیح داده شده است. این شبکه‌ها یکی از گونه‌های شبکه‌های عصبی بازگشتی هستند که در سال 1997 معرفی شدند.

 \section{\gls{reinforcementlearning}}
 
 \subsection{مقدمه و بیشینه تاریخی}
% ادوارد ثورندایک\LTRfootnote{Edward Thorndike} پدر روانشناسی مدرن در سال 1874 میلادی در ایالت ماساچوست آمریکا متولد شد. وی در اوایل قرن 20 میلادی آزمایشی انجام داد که باعث ارائه قانون اثر شد. او برای این آزمایش، گربه ای را در جعبه ای موسوم به جعبه معما قرار داد. هر کوشش درستی، از این گربه برای نجات از جعبه صورت می‌گرفت، باعث میشد ثورندایک به عنوان پاداش به او غذا بدهد. به تدریج گربه به کارهای درست خود پی برد و آنها را تکرار کرد، تا جایی که دیگر هیچ کار اشتباهی نمی کرد و بلاخره موفق به خروج از جعبه شد. ثورندایک در سال 1912 به ریاست انجمن روانشناسان، در سال 1917 به عضویت انجمن علوم، در سال 1934به ریاست انجمن علوم پیشرفته نایل آمد و در سال 1947 در سن 74 سالگی، بدرود حیات گفت. در سال 2002 رتبه ای از برترین روانشناسان تاریخ ارائه شد که ثورندایک جزء 10 روانشناس برتر تاریخ قرار گرفت. می‌توان مهم ترین کشف وی را، اثبات وجود یادگیری تقویتی در روانشناسی دانست.
 
 شاید ریچارد بلمن\LTRfootnote{Richard E. Bellman} (مخترع الگوریتم بلمن-فورد) را بتوان اولین کسی دانست که یادگیری تقویتی را وارد هوش مصنوعی ساخت. در اوایل دهه 1950 بلمن مسئله ای با عنوان «کنترل بهینه» را مطرح ساخت که با استفاده از روش های پویا در برنامه‌ریزی پویا کنترل کننده‌ها را به سمت نتیجه بهینه رهنمون می‌شد. در اواخر دهه 50 میلادی مینسکی در پایان نامه دکتری خود روش های محاسبات آزمون و خطا توسط مفهوم یادگیری تقویتی را مطرح نمود و الگوریتم های یادگیری تقویتی را پایه ریزی کرد. در کل دهه 50 میلادی را میتوان دهه تشکیل الگوریتم های محاسباتی اولیه یادگیری تقویتی دانست. در دهه 60 میلادی اولین کابرد های یادگیری تقویتی به وقوع پیوستند. در اولین تلاش ها فارلی و کلارک از یادگیری تقویتی برای تشخیص الگو استفاده کردند بدین صورت که هر بار برنامه نتیجه بهتری به دست می‌آمد او را تشویق می‌کردند. در اواخر دهه 60 میلادی، یادگیری نظارتی از یادگیری تقویتی ، مشتق شد. در یادگیری نظارتی طراح نتیجه نهایی را در دست دارد و از هوش مصنوعی می‌خواهد هر بار مسیر بین ورودی و نتیجه را طراحی کرده و هربار که برنامه، مسیر بهتری به دست می‌آورد، تشویق می‌شود. همچنین طراح نظارت مستقیم بر عملکرد عامل دارد.

 \subsection{مفاهیم و تعاریف}
 در اینجا در ابتدا مروری بر مطالب پیشین شده و سپس به سرفصل اصلی پرداخته شده است.
 یادگیری تقویتی چیست؟
 تفاوت یادگیری تقویتی با \gls{supervisedlearning} و \gls{unsupervised} در دو نقطه است:
 \begin{enumerate}
 	\item \gls{environment}: محیطی همانند هزارتو، بازی ویدیویی، بازار سهام و ...
 	\item \gls{agent}: همان هوش مصنوعی است که یاد می گیرد، چگونه عمل کند و در محیط به صورت موفقیت آمیز عمل کند.
 \end{enumerate}
 عامل از طریق تعامل تکراری با محیط، یاد می‌گیرد چگونه در محیط عمل کند. عامل یاد می‌گیرد که کدام اعمال در حالت مشخصی ارزشمندتر و مطلوب‌تر هستند. با انجام دادن عمل توسط عامل و دریافت نتایج، حالت محیط براساس پاداش دریافتی تغییر خواهد کرد. حلقه تکرار اعمال، حالات‌های پاداش به شکل 	\ref{fig:ch_lr:ae_rl} قابل تصور است.
 
 \begin{figure}[!ht]
 	\centerline{\includegraphics[width=11cm]{chaps/lr/ae_rl}}
 	\caption{تعامل عامل$-$محیط در یک فرآیند تصمیم مارکوف.}
 	\label{fig:ch_lr:ae_rl}
 \end{figure}
\noindent
 هدف عامل این است که پاداش تجمعی دریافتی مورد انتظارش را به حداکثر برساند.
 \subsubsection{ معادله بلمن}
 این معادله یک مفهوم اساسی در یادگیری تقویتی است:
 $$ s: \text{حالت}\qquad a:\ \text{عمل}\qquad R:\ \text{ پاداش}\qquad  \gamma:\ \text{فاکتور تخفیف یا کاهش}$$
ارزش انجام عمل با به تاخیر افتادن آن کاهش پیدا می کند.
 \\
 به منظور حل یک مسئله در یادگیری تقویتی با روش \lr{Q-learning} باید جدول \lr{Q} متناظر با حالات مسئله را  ساخت. این جدول یک جدول جست‌جو\LTRfootnote{lookup-table} است که پاداش آتی مورد انتظار برای هر عمل در هر حالت را نشان می‌دهد. با استفاده از این جدول می‌توان بهترین عمل را در هر حالتی انتخاب کرد.
 چگونه باید حداکثر پاداش مورد انتظار در هر حالت را حساب کرد؟ به عبارت دیگر چگونه می توان مقادیر جدول \lr{Q} را تعیین کرد؟
 \\
  مقادیر این جدول با استفاده از الگوریتم \lr{Q-learning} به صورت تکرار به روزرسانی خواهند شد. رابطه مورد نیاز برای به‌روزرسانی این جدول در محیط‌های قطعی به صورت زیر است. در این رابطه از معادله بلمن استفاده شده است.
 \begin{equation}
 	V(s) = \max_{a}\big(R(s,a)+\gamma V(s')\big)
 \end{equation}
 طبق معادله داده شده:
 \begin{itemize}
 	\item  ارزش حالت مشخص برابر است با انتخاب عملی(از میان تمام  اعمال موجود) که منجر به بیشترین ارزش خواهد شد. 
 	\item  با انجام عمل $a$ در حالت s و جمع کردن آن با ضریب کاهش $\gamma$ می‌توان به ارزش انجام عمل رسید. 
 	\item  با انجام عمل $a$ عامل به حالت جدید $s'$ انتقال می‌یابد.
 \end{itemize}

\subsubsection{\glspl{mdp}}
در ابتدا تفاوت جست‌وجوی قطعی و غیر قطعی را شرح می‌دهیم.\\
 جست‌وجوی قطعی: در این نوع اکتشاف اگر عامل، عمل $a$ را انتخاب کند با احتمال $100\%$  آن را انجام خواهد داد.\\
 جست‌وجوی غیر قطعی: به نوعی در محیط تصادفی است و در این نوع اکتشاف اگر عامل عمل $a$ را انتخاب کند ممکن است با احتمال $\epsilon>0$ اعمال دیگر را انجام دهد. 
 \\
\textbf{فرآیندهای مارکوف}
\\
 \gls{mdp} خاصیت مارکوف را داراست، اگر توزیع احتمال شرطی حالات آینده فرایند (به شرط حالات گذشته و حالات فعلی) تنها وابسته به حالت فعلی باشد و نه دنباله ای از رویدادهای پیشین آن. به منظور ساده‌سازی آن، آن چیزی که در آینده اتفاق می افتد به ان چیزی که در گذشته روی داده وابسته نیست. 
\\
\textbf{\gls{mdp}}
چهارچوبی است که عامل به منظور عمل کردن در محیط نسبتا تصادفی از آن استفاده می‌کند. به دلیل اینکه محیط تصادفی است، به صورت دقیق حالت بعدی $s'$ معلوم نیست. پس از مقدار مورد انتظار یا امید ریاضی حالت بعد استفاده می‌شود که در این صورت معادله بلمن برای حالت یک محیط غیر قطعی به صورت رابطه زیر خواهد بود.
  \begin{equation}
 	V(s) = \max_{a}\big(R(s,a)+\gamma \sum_{s'}P(s,a,s')V(s')\big)
 	\label{eq:ch_lr:bellman}
 \end{equation}


\subsection{یادگیری-\lr{Q}}
یک الگوریتم یادگیری مبتنی بر ارزش در یادگیری تقویتی است. یادگیری-\lr{Q} به عامل اجازه می‌دهد که از پاداش محیط برای یادگیری استفاده کند و به مرور زمان بهترین عمل در حالت داده شده انتخاب شود. عامل از جدول پاداش برای یادگیری استفاده می‌کند. عامل براساس عملی که انجام می‌دهد، پاداشی را در حالت فعلی دریافت خواهد کرد، سپس ارزش-\lr{Q} را به‌روزرسانی می‌کند تا بداند که این عمل مفید بوده است.
مقادیر ذخیره شده در جدول \lr{Q}،  ارزش-\lr{Q} نامیده می‌شوند. این مقادیر را می‌توان به صورت زوج مرتب  
(حالت، عمل)
نگاشت داد. ارزش-\lr{Q} برای ترکیب حالت-عمل نمایانگر "کیفیت" عملی است که می‌توان در آن حالت انجام داد. مقادیر بهتر ارزش-\lr{Q} نشان دهنده شانس بیشتر برای دریافت پاداش بیشتر است. این مقادیر  در ابتدا می‌توانند به صورت تصادفی مقداردهی اولیه شوند. عامل با در معرض محیط قرار گرفتن و دریافت پاداش‌های مختلف از محیط و انجام  اعمال مختلف، میتواند مقادیر  ارزش-\lr{Q} را به‌روزرسانی کند.

در بخش قبل به معادله \ref{eq:ch_lr:bellman} توجه کنید. در این معادله، در یادگیری-\lr{Q}، در عوض اینکه از $V(s)$ ارزش هر حالت استفاده شود از ارزش زوج حالت-عمل $Q(s,a)$ استفاده می‌شود. می‌توان گفت که ارزش-\lr{Q}  به معنای کیفیت هر عمل است. 
\\
% معادله ارزش حالت $s$ در محیط غیرقطعی به رابطه زیر است.
% \begin{equation}
% 	V(s) = \max_{a}\big(R(s,a)+\gamma \sum_{s'}P(s,a,s')V(s')\big)
% \end{equation}
برای بدست آوردن معادله $Q(s,a)$:\\
با انجام دادن یک عمل پاداش دریافتی در حالت s برابر است با $R(s,a)$\\
عامل به حالت $s'$ انتقال یافته و از آنجایی که عامل می‌تواند در چندین حالت قرار بگیرد، مقدار مورد انتطار حالت بعدی به پاداش اضافه خواهد شد.
\begin{equation}
	Q(s,a) = R(s,a)+\gamma \sum_{s'}P(s,a,s')V(s')
\end{equation}
شباهت معادله بالا با معادله بلمن به این دلیل است که ارزش حالت $s$ برابر است با حداکثر تمام مقادیر ارزش-\lr{Q}
با جایگزین کردن $V(s')$ با $Q(s',a')$ معادله زیر بدست می آید:
\begin{equation}
	V(s) = R(s,a)+\gamma \sum_{s'}P(s,a,s')\max_{a'}\big(Q(s',a')\big)
\end{equation}
این معادله بازگشتی ارزش-\lr{Q} است.

\subsubsection{\gls{temporaldifference}}
از انجایی که به دلیل غیرقطعی بودن محیط، محاسبه کردن ارزش هر حالت بسیار مشکل است، از تفاضل زمانی برای حل این مشکل استفاده می‌شود.
به منظور راحتی، از معادله قطعی بلمن استفاده می‌شود اما کماکان محیط غیرقطعی است،
\begin{equation}
	V(s) = R(s,a)+\gamma \max_{a'}\big(Q(s',a')\big)
\end{equation}
\gls{temporaldifference} به صورت زیر تعریف می‌شود.
\begin{equation}
	TD(s, a) = \max_{a}\big(R(s,a)+\gamma V(s')\big) - Q_{t-1}(s,a)
\end{equation}
جمله سمت راست در رابطه بالا، مقدار ارزش-\lr{Q} پیشین است و دو جمله سمت چپ بیان‌گر پاداش دریافتی پس از انجام عمل $a$ می‌باشد (که مقدار جدید ارزش-\lr{Q} است).
سوالی که اینجا مطرح می‌شود این است که آیا بین این مقادیر در زمان تفاوتی وجود دارد؟ بله و از این اختلاف استفاده می‌شود که به صورت رابطه \gls{temporaldifference} برای محاسبه ارزش-\lr{Q}
\begin{equation}
	Q_{t}(s,a) = Q_{t-1}(s,a) - \alpha TD_t(s,a)
\end{equation}
می‌باشد، که در اینجا $\alpha$ نرخ یادگیری است. این رابطه نحوه آپدیت ارزش-\lr{Q} در زمان را نشان می‌دهد. با جایگزین کردن تفاضل زمانی در معادله بالا معادله زیر بدست می‌آید.
\begin{equation}
	Q_{t}(s,a) = Q_{t-1}(s,a) - \alpha \left( \max_{a}\big(R(s,a)+\gamma V(s')\big) - Q_{t-1}(s,a) \right) 
\end{equation}


\subsection{\gls{deepqlearning}}
استفاده از شبکه های عصبی برای مسائل \gls{reinforcementlearning}:
حالت مورد نظر را از چندین لایه شبکه عبور داده و خروجی ارزش-\lr{Q} بدست خواهد آمد. در شکل \ref{fig:ch_lr:deepql_vs_ql} مقایسه‌ای از
 \lr{Q-learning} با \lr{Deep Q-learning}
  انجام داده شده است.
  \begin{figure}[!ht]
	\centerline{\includegraphics[width=15cm]{chaps/lr/deepql_vs_ql}}
	\caption{مقایسه‌ای از \lr{Q-learning} با \lr{Deep Q-learning}.}
	\label{fig:ch_lr:deepql_vs_ql}
\end{figure} 
 در حالت عادی هدف به طور پیوسته در هر تکرار تغییر خواهد کرد. اما در مسائل یادگیری عمیق این تغییر وجود ندارد و یادگیری پایدار است. 
از انجایی که از یک شبکه برای محاسبه ارزش پیش‌بینی شده و ارزش هدف استفاده می‌شود، ممکن است واگرایی زیادی بین این دو وجود داشته باشد. پس در \gls{deepqlearning} از دو شبکه به جای یک شبکه استفاده می‌شود. از شبکه دیگری برای تخمین هدف استفاده می‌شود. این شبکه معماری یکسانی دارد و به عنوان تابع تخمین استفاده می‌شود که پارامترهایش ثابت شده‌اند و تغییر نخواهند کرد. شکل \ref{alg:ch_lr:deepqlearning} شمایی از این دو شبکه را در این موضوع نشان می‌دهد.
  \begin{figure}[!ht]
	\centerline{\includegraphics[width=11cm]{chaps/lr/deepqlearning}}
	\caption{نمایی از ساختار \gls{deepqlearning}}
	\label{alg:ch_lr:deepqlearning}
\end{figure} 
 پس از هر $C$ تکرار، پارامترهای شبکه پیش‌بینی به شبکه هدف کپی می‌شوند. این کار منجر به روال آموزش پایدار خواهد شد. 
در ادامه در الگوریتم \ref{alg:ch_lr:deepqlearningalg} شبه‌کد \gls{deepqlearning} آورده شده است.
%reference: https://www.analyticsvidhya.com/blog/2019/04/introduction-deep-q-learning-python/
\begin{algorithm}
	\caption{\gls{deepqlearning} به همراه بازآزمایش}
	\includegraphics[width=15cm]{chaps/lr/deepqlearningalg}
	\label{alg:ch_lr:deepqlearningalg}
\end{algorithm}

در ادامه دلیل استفاده از \gls{deepqlearning} و مزیت آن بر یادگیری-\lr{Q} را بیان می‌کنیم.
در صورتی که محیط نسبتا ساده باشد الگوریتم  یادگیری-\lr{Q} به خوبی عمل می‌کند، اما در صورتی که تعداد حالات و اعمال انتخابی توسط عامل زیاد شوند، از \gls{deeplearning} به عنوان تابع تخمین زن استفاده می‌شود.
نحوه تغییر معادله بلمن با استفاده از \gls{deepqlearning} در ادامه توضیح داده شده است. 
\\
در مساله هزارتو چهار جهت حرکتی بالا، پایین، چپ و راست امکان‌پذیر است پس شبکه عصبی باید 4 مقدار را پیش‌بینی کند. شبکه می‌تواند 4 مقدار محاسبه شده فعلی را  با 4 مقدار محاسبه شده در قبل مقایسه کند:
$Q_1$ با $Q_{Target1}$ یا $Q_2$ با $Q_{Target2}$ و ...
از انجایی که شبکه های عصبی با به‌روزرسانی وزن‌های کار می‌کنند، باید معادله \gls{temporaldifference} را با این به‌روزرسانی‌ها تطبیق داد. پس می‌توان با محاسبه کردن خطای،
\begin{equation}
	L = \sum (Q - Q_{Target})^2
\end{equation}
و سپس از \gls{backpropagation} یا \gls{stochasticgradientdescent} برای آپدیت وزن‌ها استفاده کرد. با توجه به ارزش-Q از تابع \lr{softmax} برای انتخاب بهترین عمل استفاده می‌شود. با قرارگیری عامل در هر حالت جدید این فرایند تکرار خواهد شد.
\\
سیاست‌های مختلفی برای انتخاب بهترین عمل در هر حالت امکان‌پذیر است. در ادامه سه نمونه از این موارد ارائه شده است
.
\begin{latin}
	\begin{itemize}
		\item $\varepsilon$-greedy
		\item $\varepsilon$-soft
		\item Softmax
	\end{itemize}
\end{latin}
هر کدام از موارد ذکر شده در بالا برای تاثیرگذاری بیشتر در مسئله استثمار-بهره‌برداری\LTRfootnote{Exploration-exploitation} است. در صورتی که از بالاترین مقدار ممکن ارزش-Q در هر حالت یا  حالت-عمل استفاده شود، مسئله استثمار در برابر بهره‌برداری پیش خواهد آمد. \gls{agent} باید بین دانش فعلی‌اش از \gls{environment} و آنچه که در آینده می‌خواهد کشف کند مصالحه کند.
%reference: https://www.mlq.ai/deep-reinforcement-learning-q-learning/


